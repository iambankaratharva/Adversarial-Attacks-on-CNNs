# Adversarial-Attacks-on-CNNs
Utilizing the gradients of the network, we create adversarial images designed to closely resemble the originals, effectively deceiving various neural networks. This manipulation not only fools different neural networks but also reveals a security vulnerability in Convolutional Neural Networks (CNNs) that could be exploited by malicious users.
